{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trace_extract import parse_trace_file\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#device = torch.device(2 if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN_GRU, self).__init__();\n",
    "        self.gru = nn.GRU(1, 8, 1)\n",
    "        self.linear = nn.Linear(8, 1)\n",
    "        self.hidden_state = torch.randn(1, 1, 8, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):#(1, 1, 1) seq_len, batch_size, input_size\n",
    "        self.hidden_state= self.hidden_state.to(device)\n",
    "        x, self.hidden_state=self.gru(x, self.hidden_state)#(1, 1, 8)\n",
    "        self.hidden_state = self.hidden_state.detach()\n",
    "        x=x.view(-1);\n",
    "        x=self.linear(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymetric_loss(output, target, alpha=0.75):\n",
    "    if (output<target):\n",
    "        loss = 2.0*alpha*((output - target)**2)\n",
    "    else:\n",
    "        loss = 2.0*(1-alpha)*((output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_monitor():\n",
    "    def __init__(self, self_id, monitoring_id, history_size=16):\n",
    "        self.ita=100000000;\n",
    "        self.id = self_id\n",
    "        self.monitoring = monitoring_id\n",
    "        self.history_size = history_size\n",
    "        self.arrival_history = deque(maxlen=history_size)\n",
    "        #self.margin_history = np.zeros(16);\n",
    "        self.expected_arrival = 0\n",
    "        self.safety_margin = Variable(torch.tensor([0]).float()).to(device)\n",
    "        self.rnn_module = RNN_GRU().to(device);\n",
    "        self.seq_num = -1;\n",
    "        self.suspect_intervals=[]\n",
    "        self.U = 0;\n",
    "        self.lr=5e-3\n",
    "        self.decay=1e-6\n",
    "        self.optimizer=optim.SGD(self.rnn_module.parameters(),\n",
    "                             lr=self.lr,\n",
    "                             weight_decay=self.decay)\n",
    "        self.criterion = asymetric_loss#nn.MSELoss()\n",
    "        self.loss = 0;\n",
    "    \n",
    "    def forward(self, seq_num, arrival_time):\n",
    "        if (self.seq_num == -1):\n",
    "            self.seq_num=seq_num\n",
    "            self.U=arrival_time\n",
    "            self.arrival_history.append(arrival_time)\n",
    "            self.expected_arrival = self.U + self.ita;\n",
    "            x=Variable(torch.tensor([0]).float()).to(device)\n",
    "            self.safety_margin = self.rnn_module.forward(x.view(1,1,1))\n",
    "        elif (self.seq_num+1==seq_num):\n",
    "            start_time=time.time();\n",
    "            self.rnn_module.zero_grad()\n",
    "            self.seq_num=seq_num\n",
    "            if (self.expected_arrival + self.safety_margin.item()*self.ita < arrival_time):\n",
    "                self.suspect_intervals.append([self.expected_arrival + self.safety_margin, arrival_time])\n",
    "            self.arrival_history.append(arrival_time)\n",
    "            #print(\"append arrival:\", time.time()-start_time);start_time=time.time();\n",
    "            optimal_margin = (arrival_time-self.expected_arrival)/self.ita\n",
    "            #self.margin_history=np.roll(self.margin_history, -1);\n",
    "            #self.margin_history[-1]=optimal_margin\n",
    "            target = Variable(torch.tensor([optimal_margin]).float()).to(device)\n",
    "            #print(\"compute optimal:\", time.time()-start_time);start_time=time.time();\n",
    "            self.optimizer.zero_grad()\n",
    "            self.loss= self.criterion(self.safety_margin, target)\n",
    "            #print(\"compute loss:\", time.time()-start_time);start_time=time.time();\n",
    "            self.loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #print(\"back prop:\", time.time()-start_time);start_time=time.time();\n",
    "            input_x = Variable(torch.tensor([optimal_margin]).float()).to(device)            \n",
    "            self.safety_margin = self.rnn_module.forward(input_x.view(1,1,1))\n",
    "            #print(\"estimate next:\", time.time()-start_time);start_time=time.time();\n",
    "            self.cal_expectation()\n",
    "            \n",
    "        elif (self.seq_num<seq_num):\n",
    "            self.seq_num=seq_num\n",
    "            self.arrival_history.clear();\n",
    "            self.U=arrival_time\n",
    "            self.arrival_history.append(arrival_time)\n",
    "            self.expected_arrival = self.U + self.ita;\n",
    "    \n",
    "    def cal_expectation(self):\n",
    "        if (len(self.arrival_history)<self.history_size):\n",
    "            k = len(self.arrival_history);\n",
    "            temp_U = self.arrival_history[-1]/(k)+(k-1)*self.U/(k)\n",
    "            self.U = temp_U\n",
    "            self.expected_arrival = self.U + (k+1)/2*self.ita;\n",
    "        else:\n",
    "            temp = (self.arrival_history[-1]-self.arrival_history[0])/(self.history_size-1)\n",
    "            self.expected_arrival += temp\n",
    "        return self.expected_arrival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338646\n"
     ]
    }
   ],
   "source": [
    "in_path = \"../raw_data/\"\n",
    "trace_name = \"trace%d.log\"\n",
    "cur_file=in_path+trace_name%(1);\n",
    "arrival_times, c = parse_trace_file(cur_file)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoring process 0\n",
      "total receive 37658\n",
      "expected and safety margin: 47816110.468420886 -0.08144702017307281\n",
      "maximum waiting time 47816110.386973865\n",
      "actual time 47816110.46796313\n",
      "RNN loss 0\n",
      "back prop: 0.0025730133056640625\n",
      "back prop: 0.0018379688262939453\n",
      "back prop: 0.0018091201782226562\n",
      "back prop: 0.002060413360595703\n",
      "back prop: 0.0019261837005615234\n",
      "back prop: 0.0019330978393554688\n",
      "back prop: 0.0019197463989257812\n",
      "back prop: 0.0019383430480957031\n",
      "back prop: 0.0019428730010986328\n",
      "back prop: 0.0019598007202148438\n",
      "back prop: 0.0019714832305908203\n",
      "back prop: 0.0020711421966552734\n",
      "back prop: 0.0019791126251220703\n",
      "back prop: 0.0019617080688476562\n",
      "back prop: 0.0019745826721191406\n",
      "back prop: 0.0019674301147460938\n",
      "back prop: 0.0019698143005371094\n",
      "back prop: 0.001974821090698242\n",
      "back prop: 0.001935720443725586\n",
      "back prop: 0.002181529998779297\n",
      "back prop: 0.0018930435180664062\n",
      "back prop: 0.0018973350524902344\n",
      "back prop: 0.0019023418426513672\n",
      "back prop: 0.0018775463104248047\n",
      "back prop: 0.0018463134765625\n",
      "back prop: 0.0018341541290283203\n",
      "back prop: 0.00177764892578125\n",
      "back prop: 0.0018684864044189453\n",
      "back prop: 0.001850128173828125\n",
      "back prop: 0.0018613338470458984\n",
      "back prop: 0.0017611980438232422\n",
      "back prop: 0.0017852783203125\n",
      "back prop: 0.0017924308776855469\n",
      "back prop: 0.0015742778778076172\n",
      "back prop: 0.0015523433685302734\n",
      "back prop: 0.0016281604766845703\n",
      "back prop: 0.0015740394592285156\n",
      "back prop: 0.0015840530395507812\n",
      "back prop: 0.0018198490142822266\n",
      "back prop: 0.0018758773803710938\n",
      "back prop: 0.001688241958618164\n",
      "back prop: 0.0017399787902832031\n",
      "back prop: 0.0016963481903076172\n",
      "back prop: 0.0018620491027832031\n",
      "back prop: 0.0017697811126708984\n",
      "back prop: 0.0017664432525634766\n",
      "back prop: 0.0017445087432861328\n",
      "back prop: 0.001787424087524414\n",
      "back prop: 0.0018572807312011719\n",
      "back prop: 0.0017762184143066406\n",
      "back prop: 0.0016303062438964844\n",
      "back prop: 0.0018367767333984375\n",
      "back prop: 0.0016791820526123047\n",
      "back prop: 0.001617431640625\n",
      "back prop: 0.0015947818756103516\n",
      "back prop: 0.0015959739685058594\n",
      "back prop: 0.0015680789947509766\n",
      "back prop: 0.0015940666198730469\n",
      "back prop: 0.0016138553619384766\n",
      "back prop: 0.0016713142395019531\n",
      "back prop: 0.0015892982482910156\n",
      "back prop: 0.0015976428985595703\n",
      "back prop: 0.0015683174133300781\n",
      "back prop: 0.0015687942504882812\n",
      "back prop: 0.001600503921508789\n",
      "back prop: 0.0016124248504638672\n",
      "back prop: 0.0015668869018554688\n",
      "back prop: 0.0016570091247558594\n",
      "back prop: 0.0015707015991210938\n",
      "back prop: 0.0015728473663330078\n",
      "back prop: 0.0015964508056640625\n",
      "back prop: 0.001596212387084961\n",
      "back prop: 0.0016083717346191406\n",
      "back prop: 0.0016033649444580078\n",
      "back prop: 0.0015981197357177734\n",
      "back prop: 0.0016932487487792969\n",
      "back prop: 0.001573324203491211\n",
      "back prop: 0.0015864372253417969\n",
      "back prop: 0.0016143321990966797\n",
      "back prop: 0.0016117095947265625\n",
      "back prop: 0.0015721321105957031\n",
      "back prop: 0.0016105175018310547\n",
      "back prop: 0.0015954971313476562\n",
      "back prop: 0.0016639232635498047\n",
      "back prop: 0.001569509506225586\n",
      "back prop: 0.0016047954559326172\n",
      "back prop: 0.0016155242919921875\n",
      "back prop: 0.0016171932220458984\n",
      "back prop: 0.0015926361083984375\n",
      "back prop: 0.0016086101531982422\n",
      "back prop: 0.001550912857055664\n",
      "back prop: 0.0016236305236816406\n",
      "back prop: 0.0016143321990966797\n",
      "back prop: 0.0015904903411865234\n",
      "back prop: 0.001550912857055664\n",
      "back prop: 0.0016782283782958984\n",
      "back prop: 0.0015993118286132812\n",
      "back prop: 0.0015943050384521484\n",
      "back prop: 0.0015690326690673828\n",
      "back prop: 0.0016608238220214844\n",
      "back prop: 0.0016124248504638672\n",
      "back prop: 0.0016880035400390625\n",
      "back prop: 0.0016126632690429688\n",
      "back prop: 0.0015957355499267578\n",
      "back prop: 0.0015895366668701172\n",
      "back prop: 0.0015938282012939453\n",
      "back prop: 0.001573324203491211\n",
      "back prop: 0.001725912094116211\n",
      "back prop: 0.0016279220581054688\n",
      "back prop: 0.0016093254089355469\n",
      "back prop: 0.0016815662384033203\n",
      "back prop: 0.0016028881072998047\n",
      "back prop: 0.0015683174133300781\n",
      "back prop: 0.0015680789947509766\n",
      "back prop: 0.0015587806701660156\n",
      "back prop: 0.0016832351684570312\n",
      "back prop: 0.0015876293182373047\n",
      "back prop: 0.0015492439270019531\n",
      "back prop: 0.001600503921508789\n",
      "back prop: 0.0016009807586669922\n",
      "back prop: 0.0016026496887207031\n",
      "back prop: 0.0016016960144042969\n",
      "back prop: 0.0015742778778076172\n",
      "back prop: 0.0016388893127441406\n",
      "back prop: 0.0015988349914550781\n",
      "back prop: 0.0015997886657714844\n",
      "back prop: 0.0015933513641357422\n",
      "back prop: 0.0016021728515625\n",
      "back prop: 0.0016295909881591797\n",
      "back prop: 0.00162506103515625\n",
      "back prop: 0.0016341209411621094\n",
      "back prop: 0.0016620159149169922\n",
      "back prop: 0.0015690326690673828\n",
      "back prop: 0.00156402587890625\n",
      "back prop: 0.0015745162963867188\n",
      "back prop: 0.0016040802001953125\n",
      "back prop: 0.0015950202941894531\n",
      "back prop: 0.0015785694122314453\n",
      "back prop: 0.001592397689819336\n",
      "back prop: 0.0016887187957763672\n",
      "back prop: 0.001558542251586914\n",
      "back prop: 0.0015864372253417969\n",
      "back prop: 0.001569509506225586\n",
      "back prop: 0.0015578269958496094\n",
      "back prop: 0.001592397689819336\n",
      "back prop: 0.001598358154296875\n",
      "back prop: 0.0015745162963867188\n",
      "back prop: 0.0016884803771972656\n",
      "back prop: 0.0015807151794433594\n",
      "back prop: 0.0015611648559570312\n",
      "back prop: 0.0015976428985595703\n",
      "back prop: 0.0015978813171386719\n",
      "back prop: 0.0015974044799804688\n",
      "back prop: 0.00160980224609375\n",
      "back prop: 0.0016477108001708984\n",
      "back prop: 0.0017044544219970703\n",
      "back prop: 0.0016484260559082031\n",
      "back prop: 0.0015676021575927734\n",
      "back prop: 0.0015747547149658203\n",
      "back prop: 0.0015673637390136719\n",
      "back prop: 0.0015878677368164062\n",
      "back prop: 0.0016121864318847656\n",
      "back prop: 0.001621246337890625\n",
      "back prop: 0.0016851425170898438\n",
      "back prop: 0.0015974044799804688\n",
      "back prop: 0.0015757083892822266\n",
      "back prop: 0.0015752315521240234\n",
      "back prop: 0.0016028881072998047\n",
      "back prop: 0.0016133785247802734\n",
      "back prop: 0.0016026496887207031\n",
      "back prop: 0.0017006397247314453\n",
      "back prop: 0.0016818046569824219\n",
      "back prop: 0.0015981197357177734\n",
      "back prop: 0.001592397689819336\n",
      "back prop: 0.0015883445739746094\n",
      "back prop: 0.0015404224395751953\n",
      "back prop: 0.0015835762023925781\n",
      "back prop: 0.0016362667083740234\n",
      "back prop: 0.0016019344329833984\n",
      "back prop: 0.0016973018646240234\n",
      "back prop: 0.0016927719116210938\n",
      "back prop: 0.001603841781616211\n",
      "back prop: 0.0016016960144042969\n",
      "back prop: 0.0016124248504638672\n",
      "back prop: 0.0016527175903320312\n",
      "back prop: 0.0016291141510009766\n",
      "back prop: 0.0015904903411865234\n",
      "back prop: 0.0016586780548095703\n",
      "back prop: 0.0015799999237060547\n",
      "back prop: 0.0015730857849121094\n",
      "back prop: 0.0016021728515625\n",
      "back prop: 0.001644134521484375\n",
      "back prop: 0.0016219615936279297\n",
      "back prop: 0.0015916824340820312\n",
      "back prop: 0.0016138553619384766\n",
      "back prop: 0.0016880035400390625\n",
      "back prop: 0.0015978813171386719\n",
      "back prop: 0.0015990734100341797\n",
      "back prop: 0.0016698837280273438\n",
      "back prop: 0.001626729965209961\n",
      "back prop: 0.0016167163848876953\n",
      "back prop: 0.0016329288482666016\n",
      "back prop: 0.001573801040649414\n",
      "back prop: 0.0016560554504394531\n",
      "back prop: 0.0015704631805419922\n",
      "back prop: 0.001577138900756836\n",
      "back prop: 0.001611471176147461\n",
      "back prop: 0.0015909671783447266\n",
      "back prop: 0.0015766620635986328\n",
      "back prop: 0.0015957355499267578\n",
      "back prop: 0.0015947818756103516\n",
      "back prop: 0.0016930103302001953\n",
      "back prop: 0.0015916824340820312\n",
      "back prop: 0.0015785694122314453\n",
      "back prop: 0.001613616943359375\n",
      "back prop: 0.001631021499633789\n",
      "back prop: 0.0015964508056640625\n",
      "back prop: 0.0015971660614013672\n",
      "back prop: 0.0015954971313476562\n",
      "back prop: 0.0017786026000976562\n",
      "back prop: 0.0015990734100341797\n",
      "back prop: 0.0016067028045654297\n",
      "back prop: 0.001641988754272461\n",
      "back prop: 0.0016188621520996094\n",
      "back prop: 0.0016171932220458984\n",
      "back prop: 0.0016307830810546875\n",
      "back prop: 0.001603841781616211\n",
      "back prop: 0.0016870498657226562\n",
      "back prop: 0.0016067028045654297\n",
      "back prop: 0.0015807151794433594\n",
      "back prop: 0.0015799999237060547\n",
      "back prop: 0.0015773773193359375\n",
      "back prop: 0.0015828609466552734\n",
      "back prop: 0.0016143321990966797\n",
      "back prop: 0.0015974044799804688\n",
      "back prop: 0.0016603469848632812\n",
      "back prop: 0.0015769004821777344\n",
      "back prop: 0.0015947818756103516\n",
      "back prop: 0.0016019344329833984\n",
      "back prop: 0.001611948013305664\n",
      "back prop: 0.001708984375\n",
      "back prop: 0.0015683174133300781\n",
      "back prop: 0.0015549659729003906\n",
      "back prop: 0.001695871353149414\n",
      "back prop: 0.0016021728515625\n",
      "back prop: 0.001600503921508789\n",
      "back prop: 0.001604318618774414\n",
      "back prop: 0.0015971660614013672\n",
      "back prop: 0.0016429424285888672\n",
      "back prop: 0.0016350746154785156\n",
      "back prop: 0.0016317367553710938\n",
      "back prop: 0.0016994476318359375\n",
      "back prop: 0.0016045570373535156\n",
      "back prop: 0.0016429424285888672\n",
      "back prop: 0.0016207695007324219\n",
      "back prop: 0.0016283988952636719\n",
      "back prop: 0.0016298294067382812\n",
      "back prop: 0.0016045570373535156\n",
      "back prop: 0.0016102790832519531\n",
      "back prop: 0.0016930103302001953\n",
      "back prop: 0.0015795230865478516\n",
      "back prop: 0.001589059829711914\n",
      "back prop: 0.0016214847564697266\n",
      "back prop: 0.0016274452209472656\n",
      "back prop: 0.0017163753509521484\n",
      "back prop: 0.0016062259674072266\n",
      "back prop: 0.0016062259674072266\n",
      "back prop: 0.0016760826110839844\n",
      "back prop: 0.0015766620635986328\n",
      "back prop: 0.0015871524810791016\n",
      "back prop: 0.001617431640625\n",
      "back prop: 0.0015938282012939453\n",
      "back prop: 0.0016083717346191406\n",
      "back prop: 0.0015864372253417969\n",
      "back prop: 0.0015892982482910156\n",
      "back prop: 0.001691579818725586\n",
      "back prop: 0.0015985965728759766\n",
      "back prop: 0.001584768295288086\n",
      "back prop: 0.0015974044799804688\n",
      "back prop: 0.0016281604766845703\n",
      "back prop: 0.0015938282012939453\n",
      "back prop: 0.0016376972198486328\n",
      "back prop: 0.0015995502471923828\n",
      "back prop: 0.0016834735870361328\n",
      "back prop: 0.0015769004821777344\n",
      "back prop: 0.0015759468078613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back prop: 0.0016009807586669922\n",
      "back prop: 0.0016322135925292969\n",
      "back prop: 0.0016040802001953125\n",
      "back prop: 0.0016107559204101562\n",
      "back prop: 0.0016028881072998047\n",
      "back prop: 0.0016443729400634766\n",
      "back prop: 0.0015597343444824219\n",
      "back prop: 0.0015664100646972656\n",
      "back prop: 0.0016019344329833984\n",
      "back prop: 0.0015933513641357422\n",
      "back prop: 0.001611471176147461\n",
      "back prop: 0.0016069412231445312\n",
      "back prop: 0.0015981197357177734\n",
      "back prop: 0.0016682147979736328\n",
      "back prop: 0.001641988754272461\n",
      "back prop: 0.0016291141510009766\n",
      "back prop: 0.001621246337890625\n",
      "back prop: 0.0016357898712158203\n",
      "back prop: 0.0016045570373535156\n",
      "back prop: 0.0016064643859863281\n",
      "back prop: 0.0015823841094970703\n",
      "back prop: 0.0016713142395019531\n",
      "back prop: 0.001581430435180664\n",
      "back prop: 0.001619100570678711\n",
      "back prop: 0.0016455650329589844\n",
      "back prop: 0.0016050338745117188\n",
      "back prop: 0.0015804767608642578\n",
      "back prop: 0.0015788078308105469\n",
      "back prop: 0.0015799999237060547\n",
      "back prop: 0.0017018318176269531\n",
      "back prop: 0.001600503921508789\n",
      "back prop: 0.0016341209411621094\n",
      "back prop: 0.0015761852264404297\n",
      "back prop: 0.0016047954559326172\n",
      "back prop: 0.0015993118286132812\n",
      "back prop: 0.00160980224609375\n",
      "back prop: 0.001589059829711914\n",
      "back prop: 0.001714468002319336\n",
      "back prop: 0.0016050338745117188\n",
      "back prop: 0.0016214847564697266\n",
      "back prop: 0.0015995502471923828\n",
      "back prop: 0.0016102790832519531\n",
      "back prop: 0.00159454345703125\n",
      "back prop: 0.0015740394592285156\n",
      "back prop: 0.001596212387084961\n",
      "back prop: 0.0016710758209228516\n",
      "back prop: 0.001558542251586914\n",
      "back prop: 0.0016026496887207031\n",
      "back prop: 0.0015993118286132812\n",
      "back prop: 0.0016086101531982422\n",
      "back prop: 0.0015749931335449219\n",
      "back prop: 0.0016024112701416016\n",
      "back prop: 0.0015802383422851562\n",
      "back prop: 0.0016181468963623047\n",
      "back prop: 0.0015561580657958984\n",
      "back prop: 0.0016148090362548828\n",
      "back prop: 0.0016007423400878906\n",
      "back prop: 0.0016515254974365234\n",
      "back prop: 0.0016210079193115234\n",
      "back prop: 0.0017457008361816406\n",
      "back prop: 0.0016374588012695312\n",
      "back prop: 0.0017251968383789062\n",
      "back prop: 0.0016040802001953125\n",
      "back prop: 0.0016095638275146484\n",
      "back prop: 0.0015897750854492188\n",
      "back prop: 0.0015821456909179688\n",
      "back prop: 0.0015976428985595703\n",
      "back prop: 0.0016281604766845703\n",
      "back prop: 0.001598358154296875\n",
      "back prop: 0.0017094612121582031\n",
      "back prop: 0.0016112327575683594\n",
      "back prop: 0.0015778541564941406\n",
      "back prop: 0.001583099365234375\n",
      "back prop: 0.001592397689819336\n",
      "back prop: 0.0016121864318847656\n",
      "back prop: 0.0016973018646240234\n",
      "back prop: 0.0016074180603027344\n",
      "back prop: 0.0017688274383544922\n",
      "back prop: 0.0016810894012451172\n",
      "back prop: 0.0015919208526611328\n",
      "back prop: 0.001588582992553711\n",
      "back prop: 0.0016350746154785156\n",
      "back prop: 0.001600027084350586\n",
      "back prop: 0.0015969276428222656\n",
      "back prop: 0.0015795230865478516\n",
      "back prop: 0.0016818046569824219\n",
      "back prop: 0.0015842914581298828\n",
      "back prop: 0.0015769004821777344\n",
      "back prop: 0.001615762710571289\n",
      "back prop: 0.001691579818725586\n",
      "back prop: 0.0016171932220458984\n",
      "back prop: 0.0015842914581298828\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a981ec315d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"actual time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RNN loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuspect_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-5f086ce73910>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq_num, arrival_time)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#print(\"compute loss:\", time.time()-start_time);start_time=time.time();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"back prop:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(1):\n",
    "    error_history=[]\n",
    "    if (j==1): continue;\n",
    "    print(\"monitoring process %d\"%(j))\n",
    "    print(\"total receive %d\"%(len(arrival_times[j])))\n",
    "    monitor = RNN_monitor(1, j)\n",
    "    for (k,trace) in enumerate(arrival_times[j]):\n",
    "        n=trace[0]\n",
    "        t=trace[1]\n",
    "        expt=monitor.expected_arrival/1e9\n",
    "        sft=monitor.safety_margin.item()\n",
    "        maxt=expt+sft\n",
    "        error_history.append(t/1e9-maxt)\n",
    "        if (k%10000==1):\n",
    "            print(\"expected and safety margin:\", expt, sft)\n",
    "            print(\"maximum waiting time\", maxt)\n",
    "            print(\"actual time\", t/1e9)\n",
    "            print(\"RNN loss\", monitor.loss)\n",
    "        monitor.forward(n, t)\n",
    "    print(len(monitor.suspect_intervals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_history[1:])\n",
    "plt.ylim(-0.01, 0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (46) : all CUDA-capable devices are busy or unavailable at /opt/conda/conda-bld/pytorch_1544174967633/work/torch/csrc/generic/serialization.cpp:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7acbd3dab302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../output_data/CNN_suspect%d_%d.pkl\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuspect_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrival_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrival_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (46) : all CUDA-capable devices are busy or unavailable at /opt/conda/conda-bld/pytorch_1544174967633/work/torch/csrc/generic/serialization.cpp:15"
     ]
    }
   ],
   "source": [
    "\n",
    "f=open(\"../output_data/RNN_suspect%d_%d.pkl\"%(1,j), \"wb\");\n",
    "pkl.dump(monitor.suspect_intervals, f)\n",
    "pkl.dump(arrival_times[j][0], f)\n",
    "pkl.dump(arrival_times[j][-1], f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
